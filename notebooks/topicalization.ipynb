{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c9f4e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp_models.pretrained import load_predictor\n",
    "from allennlp_models.pretrained import get_pretrained_models\n",
    "\n",
    "import checklist\n",
    "from checklist.editor import Editor\n",
    "from checklist.perturb import Perturb\n",
    "from checklist.test_types import MFT, INV, DIR\n",
    "from checklist.expect import Expect\n",
    "\n",
    "from checklist.pred_wrapper import PredictorWrapper\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fae36a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16ecff60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_topic(sentence):\n",
    "    string_split = sentence.split()\n",
    "    topic = string_split[-2:]\n",
    "    topic[0] = topic[0].capitalize()\n",
    "    topic = words = [w.replace(\".\", \",\") for w in topic]\n",
    "    not_topic = string_split[:-2]\n",
    "    if not_topic[0] != \"I\":\n",
    "        not_topic[0] = not_topic[0].lower()\n",
    "    rebuilt_sentence_list = topic + not_topic\n",
    "    rebuilt_sentence = \" \".join(rebuilt_sentence_list)+\".\"\n",
    "    return rebuilt_sentence\n",
    "\n",
    "def get_pp_tags(sentence):\n",
    "    output = srl_predictor.predict(sentence)\n",
    "    if len(output['verbs']) >= 1:\n",
    "        pp_tags = output['verbs'][1]['tags']\n",
    "    else:\n",
    "        pp_tags = []\n",
    "    return pp_tags\n",
    "\n",
    "def get_pp_descr(sentence):\n",
    "    output = srl_predictor.predict(sentence)\n",
    "    if len(output['verbs']) >= 1:\n",
    "        pp_descr = output['verbs'][1]['description']\n",
    "    else:\n",
    "        pp_descr = []\n",
    "    return pp_descr\n",
    "\n",
    "def find_final_min_one_arg(list_of_arg):\n",
    "    if list_of_arg:\n",
    "        element = list_of_arg[-3]\n",
    "    else:\n",
    "        element = 'missed_verb'\n",
    "    return element\n",
    "\n",
    "def find_first_arg(list_of_arg):\n",
    "    if list_of_arg:\n",
    "        element = list_of_arg[0]\n",
    "    else:\n",
    "        element = 'missed_verb'\n",
    "    return element\n",
    "\n",
    "def get_loc_tags(sentence):\n",
    "    output = srl_predictor.predict(sentence)\n",
    "    loc_tags = output['verbs'][1]['tags'][-2]\n",
    "    return loc_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac43948b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/syb/opt/anaconda3/envs/the/lib/python3.9/site-packages/nltk/corpus/reader/wordnet.py:579: UserWarning: Discarded redundant search for Synset('lunch_meat.n.01') at depth 3\n",
      "  for synset in acyclic_breadth_first(self, rel, depth):\n",
      "/Users/syb/opt/anaconda3/envs/the/lib/python3.9/site-packages/nltk/corpus/reader/wordnet.py:579: UserWarning: Discarded redundant search for Synset('headcheese.n.01') at depth 3\n",
      "  for synset in acyclic_breadth_first(self, rel, depth):\n",
      "/Users/syb/opt/anaconda3/envs/the/lib/python3.9/site-packages/nltk/corpus/reader/wordnet.py:579: UserWarning: Discarded redundant search for Synset('haslet.n.01') at depth 3\n",
      "  for synset in acyclic_breadth_first(self, rel, depth):\n",
      "/Users/syb/opt/anaconda3/envs/the/lib/python3.9/site-packages/nltk/corpus/reader/wordnet.py:579: UserWarning: Discarded redundant search for Synset('leg_of_lamb.n.01') at depth 5\n",
      "  for synset in acyclic_breadth_first(self, rel, depth):\n",
      "/Users/syb/opt/anaconda3/envs/the/lib/python3.9/site-packages/nltk/corpus/reader/wordnet.py:579: UserWarning: Discarded redundant search for Synset('rack_of_lamb.n.01') at depth 5\n",
      "  for synset in acyclic_breadth_first(self, rel, depth):\n"
     ]
    }
   ],
   "source": [
    "food = wn.synset('food.n.02')\n",
    "food = list(set([w for s in food.closure(lambda s:s.hyponyms()) for w in s.lemma_names()]))\n",
    "singular_food =  [x.lower() for x in food if \"_\" not in x ]\n",
    "\n",
    "# random.seed(18)\n",
    "# sampled_list = random.sample(singular_food, 100)\n",
    "# print(sampled_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "284ad4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_topicalization_neg = []\n",
    "editor = Editor()\n",
    "\n",
    "test_data = editor.template(\"I wont eat that {singular_food}.\",\n",
    "                            singular_food = singular_food,\n",
    "                            meta=True, \n",
    "                            seed=42,  \n",
    "                            nsamples=nsamples,\n",
    "                            remove_duplicates=True)\n",
    "list_topicalization_neg.append(test_data['data'])\n",
    "\n",
    "#flatten list\n",
    "list_topicalization_neg = [x for xs in list_topicalization_neg for x in xs]\n",
    "\n",
    "list_topicalization = []\n",
    "\n",
    "editor = Editor()\n",
    "test_data = editor.template(\"I will eat that {singular_food}.\",\n",
    "                            singular_food = singular_food,\n",
    "                            meta=True, \n",
    "                            seed=42,  \n",
    "                            nsamples=nsamples,\n",
    "                            remove_duplicates=True)\n",
    "list_topicalization.append(test_data['data'])\n",
    "\n",
    "#flatten list\n",
    "list_topicalization = [x for xs in list_topicalization for x in xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b8498d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lerc is not a registered model.\n"
     ]
    }
   ],
   "source": [
    "srl_predictor = load_predictor('structured-prediction-srl')\n",
    "\n",
    "df = pd.DataFrame(list_topicalization_neg)\n",
    "df[1] = df[0].apply(switch_topic)\n",
    "df.rename(columns = {0:'original', 1:'switched'}, inplace = True)\n",
    "\n",
    "df['tags_original'] = df['original'].apply(get_pp_tags)\n",
    "df['descr_original'] = df['original'].apply(get_pp_descr)\n",
    "\n",
    "df['tags_switched'] = df['switched'].apply(get_pp_tags)\n",
    "df['descr_switched'] = df['switched'].apply(get_pp_descr)\n",
    "\n",
    "df['final-1_arg_original'] = df['tags_original'].apply(find_final_min_one_arg)\n",
    "df['first_arg_switch'] = df['tags_switched'].apply(find_first_arg)\n",
    "\n",
    "df['first_arg_switch'] = df['first_arg_switch'].str.replace('B-', '')\n",
    "df['first_arg_switch'] = df['first_arg_switch'].str.replace('I-', '')\n",
    "\n",
    "df['final-1_arg_original'] = df['final-1_arg_original'].str.replace('I-', '')\n",
    "df['final-1_arg_original'] = df['final-1_arg_original'].str.replace('B-', '')\n",
    "\n",
    "df['orginal_switched_match'] = df['final-1_arg_original'] == df['first_arg_switch']\n",
    "\n",
    "df['original'].to_csv(\"../datasets/topicalization/negated.txt\", header=None, index=False)\n",
    "df.to_csv(\"../results/topicalization/results_negated_bilstm.csv\")\n",
    "\n",
    "df_error_neg_bilstm = df[df['orginal_switched_match'] == False][['descr_original', 'descr_switched']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1350ef0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11e1bed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list_topicalization)\n",
    "df[1] = df[0].apply(switch_topic)\n",
    "df.rename(columns = {0:'original', 1:'switched'}, inplace = True)\n",
    "\n",
    "df['tags_original'] = df['original'].apply(get_pp_tags)\n",
    "df['descr_original'] = df['original'].apply(get_pp_descr)\n",
    "\n",
    "df['tags_switched'] = df['switched'].apply(get_pp_tags)\n",
    "df['descr_switched'] = df['switched'].apply(get_pp_descr)\n",
    "\n",
    "df['final-1_arg_original'] = df['tags_original'].apply(find_final_min_one_arg)\n",
    "df['first_arg_switch'] = df['tags_switched'].apply(find_first_arg)\n",
    "\n",
    "df['first_arg_switch'] = df['first_arg_switch'].str.replace('B-', '')\n",
    "df['first_arg_switch'] = df['first_arg_switch'].str.replace('I-', '')\n",
    "\n",
    "df['final-1_arg_original'] = df['final-1_arg_original'].str.replace('I-', '')\n",
    "df['final-1_arg_original'] = df['final-1_arg_original'].str.replace('B-', '')\n",
    "\n",
    "df['orginal_switched_match'] = df['final-1_arg_original'] == df['first_arg_switch']\n",
    "df.to_csv(\"../results/topicalization/results_simple_bilstm.csv\")\n",
    "\n",
    "df_error_simple_bilstm = df[df['orginal_switched_match'] == False][['descr_original', 'descr_switched']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fc5dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5490663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35496ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lerc is not a registered model.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "srl_predictor = load_predictor('structured-prediction-srl-bert')\n",
    "\n",
    "df = pd.DataFrame(list_topicalization)\n",
    "df[1] = df[0].apply(switch_topic)\n",
    "df.rename(columns = {0:'original', 1:'switched'}, inplace = True)\n",
    "\n",
    "df['tags_original'] = df['original'].apply(get_pp_tags)\n",
    "df['descr_original'] = df['original'].apply(get_pp_descr)\n",
    "\n",
    "df['tags_switched'] = df['switched'].apply(get_pp_tags)\n",
    "df['descr_switched'] = df['switched'].apply(get_pp_descr)\n",
    "\n",
    "df['final-1_arg_original'] = df['tags_original'].apply(find_final_min_one_arg)\n",
    "df['first_arg_switch'] = df['tags_switched'].apply(find_first_arg)\n",
    "\n",
    "df['first_arg_switch'] = df['first_arg_switch'].str.replace('B-', '')\n",
    "df['first_arg_switch'] = df['first_arg_switch'].str.replace('I-', '')\n",
    "\n",
    "df['final-1_arg_original'] = df['final-1_arg_original'].str.replace('I-', '')\n",
    "df['final-1_arg_original'] = df['final-1_arg_original'].str.replace('B-', '')\n",
    "\n",
    "df['orginal_switched_match'] = df['final-1_arg_original'] == df['first_arg_switch']\n",
    "df.to_csv(\"../results/topicalization/results_simple_bert.csv\")\n",
    "\n",
    "df_error_simple_bert = df[df['orginal_switched_match'] == False][['descr_original', 'descr_switched']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e825ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list_topicalization_neg)\n",
    "df[1] = df[0].apply(switch_topic)\n",
    "df.rename(columns = {0:'original', 1:'switched'}, inplace = True)\n",
    "\n",
    "df['tags_original'] = df['original'].apply(get_pp_tags)\n",
    "df['descr_original'] = df['original'].apply(get_pp_descr)\n",
    "\n",
    "df['tags_switched'] = df['switched'].apply(get_pp_tags)\n",
    "df['descr_switched'] = df['switched'].apply(get_pp_descr)\n",
    "\n",
    "df['final-1_arg_original'] = df['tags_original'].apply(find_final_min_one_arg)\n",
    "df['first_arg_switch'] = df['tags_switched'].apply(find_first_arg)\n",
    "\n",
    "df['first_arg_switch'] = df['first_arg_switch'].str.replace('B-', '')\n",
    "df['first_arg_switch'] = df['first_arg_switch'].str.replace('I-', '')\n",
    "\n",
    "df['final-1_arg_original'] = df['final-1_arg_original'].str.replace('I-', '')\n",
    "df['final-1_arg_original'] = df['final-1_arg_original'].str.replace('B-', '')\n",
    "\n",
    "df['orginal_switched_match'] = df['final-1_arg_original'] == df['first_arg_switch']\n",
    "\n",
    "df_error_neg_bert = df[df['orginal_switched_match'] == False][['descr_original', 'descr_switched']]\n",
    "df.to_csv(\"../results/topicalization/results_neg_bert.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1aaa5dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "failure_simple_bert = len(df_error_simple_bert)/len(df)*100\n",
    "failure_neg_bert = len(df_error_neg_bert)/len(df)*100\n",
    "failure_simple_bilstm = len(df_error_simple_bilstm)/len(df)*100\n",
    "failure_neg_bilstm = len(df_error_neg_bilstm)/len(df)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2922d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT\n",
      "Simple:  10.0\n",
      "Negated:  21.0\n",
      "bilstm\n",
      "Simple:  4.0\n",
      "Negated:  3.0\n"
     ]
    }
   ],
   "source": [
    "print(\"BERT\")\n",
    "print(\"Simple: \", failure_simple_bert)\n",
    "print(\"Negated: \", failure_neg_bert)\n",
    "print(\"bilstm\")\n",
    "print(\"Simple: \", failure_simple_bilstm)\n",
    "print(\"Negated: \", failure_neg_bilstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907d2cf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7571a27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "the",
   "language": "python",
   "name": "the"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
